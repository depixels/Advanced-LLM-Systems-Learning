# 00: Foundations of Advanced LLM Systems

This section lays the groundwork for understanding advanced Large Language Model (LLM) systems. It covers core architectural components, training methodologies, underlying technologies, and essential theoretical concepts that form the basis of modern LLMs.

## Navigation

Explore the fundamental topics covered in this section:

1.  [**LLM Architectures**](./01_llm_architectures/README.md): Delve into the core building blocks and designs of Large Language Models, starting with Transformer fundamentals.
2.  [**Training Paradigms**](./02_training_paradigms/README.md): Understand the different methods and strategies used to train large-scale models.
3.  [**Distributed Systems**](./03_distributed_systems/README.md): Learn about the systems and techniques required to handle the massive computational load of LLM training and inference.
4.  [**RLHF Fundamentals**](./04_rlhf_fundamentals/README.md): Explore Reinforcement Learning from Human Feedback, a key technique for aligning LLMs with human preferences.
5.  [**Model Compression**](./05_model_compression/README.md): Discover methods to make large models smaller and more efficient without significant performance loss.
6.  [**Hardware Foundations**](./06_hardware_foundations/README.md): Gain insights into the specialized hardware (like GPUs and TPUs) that powers LLMs.
7.  [**Mathematical Foundations**](./07_mathematical_foundations/README.md): Review the essential mathematical concepts underpinning LLM operations.
8.  [**Software Foundations**](./08_software_foundations/README.md): Understand the software libraries, frameworks, and tools commonly used in the LLM ecosystem.

*   [**Resources**](./resources/): Find supplementary materials, links, and other resources related to the foundational topics.

---

Navigate through these sections to build a comprehensive understanding of the fundamentals required for advanced LLM systems development and research.
